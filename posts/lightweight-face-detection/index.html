<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="icon" href="/static/favicon.ico" type="image/x-icon">

  <link rel="stylesheet" type="text/css" href="/static/asciinema-player.css" />
  <script>MathJax = {tex: {inlineMath: [["$", "$"]], displayMath: [["$$", "$$"]], processEscapes: !1}}</script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

  <style>
    /* HLJS CODE HIGHLIGHTING */
    pre code.hljs {
      display: block;
      overflow-x: auto;
      padding: 1em
    }

    code.hljs {
      padding: 3px 5px
    }

    .hljs {
      background: #fefefe;
      color: #545454
    }

    .hljs-comment,
    .hljs-quote {
      color: #696969
    }

    .hljs-deletion,
    .hljs-name,
    .hljs-regexp,
    .hljs-selector-class,
    .hljs-selector-id,
    .hljs-tag,
    .hljs-template-variable,
    .hljs-variable {
      color: #d91e18
    }

    .hljs-attribute,
    .hljs-built_in,
    .hljs-link,
    .hljs-literal,
    .hljs-meta,
    .hljs-number,
    .hljs-params,
    .hljs-type {
      color: #aa5d00
    }

    .hljs-addition,
    .hljs-bullet,
    .hljs-string,
    .hljs-symbol {
      color: green
    }

    .hljs-section,
    .hljs-title {
      color: #007faa
    }

    .hljs-keyword,
    .hljs-selector-tag {
      color: #7928a1
    }

    .hljs-emphasis {
      font-style: italic
    }

    .hljs-strong {
      font-weight: 700
    }

    @media screen and (-ms-high-contrast:active) {

      .hljs-addition,
      .hljs-attribute,
      .hljs-built_in,
      .hljs-bullet,
      .hljs-comment,
      .hljs-link,
      .hljs-literal,
      .hljs-meta,
      .hljs-number,
      .hljs-params,
      .hljs-quote,
      .hljs-string,
      .hljs-symbol,
      .hljs-type {
        color: highlight
      }

      .hljs-keyword,
      .hljs-selector-tag {
        font-weight: 700
      }
    }

    /* HLJS CODE HIGHLIGHTING END */

    header div a::before {
      content: '';
      display: block;
      position: absolute;
      bottom: 14%;
      left: 0;
      width: 100%;
      height: 40%;
      transform: rotate(-1deg);
      background-color: orange;
      z-index: -1;
      opacity: .3;
      transition: opacity .2s ease-in-out;
    }

    header div a:hover::before {
      opacity: .8;
    }

    header div a {
      font-size: 1.8rem;
      display: inline-block;
      position: relative;
      text-decoration: none;
      color: inherit;
    }

    header {
      margin-top: 1rem;
    }

    header>div {
      text-align: center;
    }

    body {
      padding: 0 1rem;
      margin: 0 auto;
      color: #333333;
      max-width: 36rem;
      line-height: 1.55;
    }

    @media screen and (min-width:70ch) {
      main {
        word-break: auto-phrase;
        text-align: justify;
        text-justify: inter-character;
        hyphens: auto;
        hyphenate-limit-lines: 2;
      }
    }

    /* what follows are common sense defaults for all pages that inherit this layout.html */
    h1 {
      font-size: 2.25rem;
      line-height: 2.5rem;
      text-align: center;
    }

    ul,
    ol {
      text-align: left;
    }

    hr {
      margin: 32px 0;
    }

    li {
      margin: 4px 0;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      line-height: 1.2;
    }

    /* From https://developer.mozilla.org/en-US/docs/Web/HTML/Element/kbd */
    kbd>kbd {
      text-indent: 0;
      background-color: #eee;
      border-radius: 3px;
      border: 1px solid #b4b4b4;
      box-shadow:
        0 1px 1px rgba(0, 0, 0, 0.2),
        0 2px 0 0 rgba(255, 255, 255, 0.7) inset;
      color: #333;
      display: inline-block;
      font-size: 0.9em;
      font-weight: 700;
      line-height: 1;
      padding: 2px 4px;
      white-space: nowrap;
    }

    aside {
      border-left: 2px solid gray;
      border-radius: 2px;
      padding-left: 16px;
      margin: 0;
      margin-left: 32px;
    }

    code,
    pre {
      font-family: ui-monospace, 'Cascadia Code', 'Source Code Pro', Menlo, Consolas, 'DejaVu Sans Mono', monospace !important;
      overflow-y: hidden;
      hyphens: auto;
    }

    :not(pre)>code {
      font-size: 90%;
    }

    p+p {
      margin-top: 1.3em;
    }

    pre {
      border-radius: 8px;
      background-color: #fcfcfc;
      border: 1px solid #f2f2f2;
      padding: 4px 7px;
      overflow-x: auto;
      font-size: .8rem;
    }

    .img+pre {
      margin-top: 1rem;
    }

    pre:has(+.img) {
      margin-bottom: 1rem;
    }

    [id^="asciinema-cast-"] {
      max-width: 100%;
      border-radius: 8px;
      height: min-content;
      display: block;
      margin: 0 auto;
    }

    img {
      max-width: 100%;
      border-radius: 8px;
      height: auto;
      display: block;
      margin: 0 auto;
    }

    .hljs-meta.prompt_ {
      user-select: none;
    }


    summary {
      cursor: pointer;
      user-select: none;

      display: flex;
      align-items: center;
      justify-content: flex-end;
      margin-bottom: 20px;
    }

    details>summary::before {
      content: '>';
      font-weight: 700;
      padding-right: 10px;
    }

    details[open]>summary::before {
      content: '^';
    }

    summary::after {
      content: "";
      flex-grow: 1;
      height: 1px;
      background-color: #333;
      margin-left: 10px;
    }

    .code-preview.collapsed {
      position: relative;
    }

    .code-preview.collapsed pre {
      max-height: 300px;
      position: relative;
    }

    .code-preview.collapsed pre::after {
      content: "";
      position: absolute;
      bottom: 0;
      left: 0;
      width: 100%;
      height: 300px;
      background: linear-gradient(to bottom, transparent 25%, 75%, gray);
      pointer-events: none;
    }

    .code-preview .expand-btn {
      position: absolute;
      left: 50%;
      bottom: 10%;
      transform: translate(-50%, 10%);
      border: 1px solid black;
      border-radius: 4px;
      background: none;
      background-color: rgba(239, 239, 239, 0.7);
      padding: 6px;
      width: 120px;
    }

    .code-preview .expand-btn:hover {
      background-color: rgba(239, 239, 239);
    }

    .code-preview:not(.collapsed) .expand-btn {
      position: sticky;
      left: 50%;
      transform: translate(-50%);
    }
  </style><title>Fast &amp; Lightweight Millisecond-level Face Detector in Python - Kevin Cao</title>
<meta name="description" content="I thought I'll share some simple Python code to detect faces that makes use of
YuNet: A Tiny Millisecond-level Face Detector
[https://link.springer.com/article/10.1007/s11633-023-1423-y]. I adapted the
code from here
[https://gist.github.com/UnaNancyOwen/3f06d4a0d04f3a75cc62563aafbac332] and
snatched the model file yunet.onnx from here
[https://github.com/opencv/opencv_zoo/tree/main/models/face_detection_yunet]—I
couldn't get the int8 quant to perform perform consistently, so I would just go
for the already very light base model." />
<style>
  h2,
  h3,
  h4,
  h5,
  h6 {
    margin-top: 32px;
    margin-bottom: 12px;
    margin-left: -28px;
    text-decoration: underline;
  }

  @media (min-width: 42rem) {
    pre {
      margin-left: -2rem;
      width: calc(100% + 4rem);
    }
  }

  @media (min-width: 42rem) {
    img {
      margin-left: -2rem;
	  max-width: calc(100% + 4rem) !important;
      width: calc(100% + 4rem);
    }
  }

  @media (min-width: 42rem) {
	[id^="asciinema-cast-"] {
      margin-left: -2rem;
	  max-width: calc(100% + 4rem) !important;
      width: calc(100% + 4rem);
    }
  }

  header>h1 {
    color: #333;
    padding: 0 1rem;
    text-align: center;
  }
</style></head>

<body><header><div>
      <a href="/">back to homepage</a>
    </div></header>

  <main><article>
  <header>
    <h1>Fast &amp; Lightweight Millisecond-level Face Detector in Python</h1>
    <div style="padding-bottom:1rem; text-align:center"><time>Jan 2, 2024</time></div>
  </header>
  <p>I thought I&#039;ll share some simple Python code to detect faces that makes use of <a href="https://link.springer.com/article/10.1007/s11633-023-1423-y">YuNet: A Tiny Millisecond-level Face Detector</a>. I adapted the code from <a href="https://gist.github.com/UnaNancyOwen/3f06d4a0d04f3a75cc62563aafbac332">here</a> and snatched the model file <code>yunet.onnx</code> from <a href="https://github.com/opencv/opencv_zoo/tree/main/models/face_detection_yunet">here</a>—I couldn&#039;t get the int8 quant to perform perform consistently, so I would just go for the already very light base model.</p><pre ><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> cv2

detector = cv2.FaceDetectorYN_create(<span class="hljs-string">&#x27;yunet.onnx&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>, (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>))
capture = cv2.VideoCapture(<span class="hljs-number">0</span>)

SCALE = <span class="hljs-number">1</span>

<span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
    _, img = capture.read()
    h, w, channels = img.shape
    <span class="hljs-keyword">assert</span>(channels == <span class="hljs-number">3</span>)
    w //= SCALE 
    h //= SCALE 

    detector.setInputSize((w,h))
    _, faces = detector.detect(cv2.resize(img, (w,h)))
    <span class="hljs-keyword">if</span> faces <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
        faces = []

    <span class="hljs-keyword">for</span> face <span class="hljs-keyword">in</span> faces:
        face = [<span class="hljs-built_in">int</span>(i)*SCALE <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> face]
        color = (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>)

        box = face[:<span class="hljs-number">4</span>]
        cv2.rectangle(img, box, color, <span class="hljs-number">2</span>, cv2.LINE_AA)

        landmarks = face[<span class="hljs-number">4</span>:<span class="hljs-built_in">len</span>(face)-<span class="hljs-number">1</span>]
        landmarks = np.array_split(landmarks, <span class="hljs-built_in">len</span>(landmarks) / <span class="hljs-number">2</span>)
        <span class="hljs-keyword">for</span> landmark <span class="hljs-keyword">in</span> landmarks:
            cv2.circle(img, landmark, <span class="hljs-number">5</span>, color, -<span class="hljs-number">1</span>, cv2.LINE_AA)

    cv2.imshow(<span class="hljs-string">&#x27;&#x27;</span>, img)

    key = cv2.waitKey(<span class="hljs-number">10</span>)
    <span class="hljs-keyword">if</span> key == <span class="hljs-built_in">ord</span>(<span class="hljs-string">&#x27;q&#x27;</span>):
        <span class="hljs-keyword">break</span>

cv2.destroyAllWindows()</pre><p>I added the <code>SCALE</code> constant that can scale down the webcam image before feeding it into YuNet to process. When set to 4 it results in an 86% reduction in CPU usage—on my machine that means the code uses only around 0.3% of my total CPU. I could see myself in the future incorporating this code into some project that involves detecting a users face.</p>
</article></main></body>

</html>